{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab5d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as exc\n",
    "from openpyxl import workbook as wb\n",
    "from openpyxl import load_workbook\n",
    "import xlrd\n",
    "import pyexcel as p\n",
    "import os\n",
    "from io import StringIO\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da0b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_dict = {\"Scarify\":[\"Scarify\"], \"Strip Site\":[\"Strip Site\"], \n",
    "             \"Soil Correction\":[\"Soil Correction\", \"OX\",\"OE\", \"Over Ex\", \"Excavate & Re-compact\", \"Over-Ex\", \"Excavate & Recompact\"],\n",
    "             \"Ex Retainining Wall\":[\"Excavate Site Retaining\", \"Excavate MSE\", \"Exc Retaining\", \"Exc Site Retn Walls\"],\n",
    "             \"Export\":[\"Export\", \"Exp\"], \"Import\":[\"Import\", \"Imp\"],\n",
    "             \"Ex Frost footing\": [\"Exc Fro\", \"Excavate Fro\", \"Footing Excavation\"], \n",
    "             \"Ex Trash Enc\":[\"Excavate Trash\", \"Exc Trash\"],\n",
    "             \"Cut to Fill\":[\"Cut To Fill\", \"Utility Spoils - Site Fill\", \"Building Pad Fill w/ Spoils\"],\n",
    "             \"Cut to Stockpile\":[\"Cut to Stockpile\", \"Load & Stockpile\"],\n",
    "             \"Handle spoils\":[\"Handle Utility Spoils\", \"Handle Foundation Spoils\", \"Handle Spoils\", \"Handle & Stockpile\"],\n",
    "             \"Double Handle\":[\"Double Handle\"], \"Cut in C&G\":[\"Cut In C\", \"Cut-in C\", \"Grade C&G\"],\n",
    "             \"Ex Elevator\":[\"Excavate Elevator\"],\n",
    "             \"Grade Landscape\":[\"grade Landscape\", \"grade Green\", \"Landscape\"],\n",
    "             \"Grade Parkinglots and Roads\":[\"Grade Boulevards\",\"Grade Asphalt\", \"Grade Parking\", \"Grade Pkg\", \"Grade Main Roads\"],\n",
    "             \"Grade SW\":[\"Grade Sidewalks\", \"Grade Walks\", \"Exterior Slabs\", \"grade Brick Pavers\", \"Grade SW\"],\n",
    "             \"Export\":[\"Export\"],\n",
    "             \"Grade BLDG\": [\"Grade Bldg\", \"Grade Building\", \"Grade Structural\"],\n",
    "             \"Drain Tile\":[\"Drain\"],\n",
    "             \"Backfill Int\":[\"Backfill Int\", \"Footing Backfill\"],\n",
    "             \"Backfill Ext\":[\"Backfill Ext\"],\n",
    "             \"Backfill Elevator\":[\"Backfill Elevator\"],\n",
    "             \"Backfill Trash\":[\"Backfill Trash\"], \"Backfill Frost\": [\"Backfill Frost\"],\n",
    "             \"High Backfill\": [\"High Backfill\"], \"Grade Class X\":[\"Grade Class\"],\n",
    "             \"Excavate Interior\":[\"Excavate Int\", \"Excavate Thickened\", \"Excavate Grade Beams\", \"Exc Int\"],\n",
    "             \"Excavate Exterior\":[\"Excavate Ext\", \"Exc Ext\"], \"Grade Pond\":[\"Basin Grading\",\"Grade Pond\" , \"Grade Detention Pond\"],\n",
    "             \"Assist shoring\":[\"Assist Shoring\"],\n",
    "             \"Stairs\":[\"Stairs\"], \"Place Strippings\":[\"Place Stripping\"],\n",
    "             \"Street Sweep\":[\"Street Sweeping\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a4b4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_date(df, item):\n",
    "    job_date = item.split(' ',1)[-1]\n",
    "    date = re.sub(\"[^\\d\\.]\", \"\", job_date)\n",
    "    date = date.replace(\".\", \"\")[-8:]\n",
    "    job = str(df.columns[0]).split(' ', 1)[1]\n",
    "    edit_date = pd.to_datetime(date, format='%Y%m%d', errors='coerce')\n",
    "#     print(edit_date, job, item)\n",
    "#     print(date)\n",
    "#     edit_date = pd.to_datetime(str(df.iloc[0,0]).split(' ')[0], errors='coerce')\n",
    "#     attendance = str(df.iloc[0,0]).split(' ',1)[1]\n",
    "    return job, edit_date\n",
    "#\n",
    "\n",
    "def job_code(completed_path):\n",
    "    files = []\n",
    "    for item in os.listdir(completed_path):\n",
    "        job_code = item.split(' ')[1]\n",
    "        files.append(job_code)\n",
    "    files= pd.unique(files).tolist()\n",
    "    return files\n",
    "    \n",
    "    \n",
    "def lat_old(files):\n",
    "    lat_file_list = []\n",
    "#     old_file_list = []\n",
    "    for file in files:\n",
    "        job_files = [os.path.join(completed_path, x) for x in os.listdir(completed_path) if file in x]\n",
    "        latest_file = max(job_files, key=os.path.getctime)\n",
    "        lat_file_list.append((latest_file))\n",
    "    lat_file_list = pd.unique(lat_file_list) \n",
    "    return lat_file_list\n",
    "\n",
    "def files_to_dfs(file_list):\n",
    "    df_list = []\n",
    "    for file in file_list:\n",
    "        num_sheet = len(pd.ExcelFile(file).sheet_names)\n",
    "        for sheet in range(0,num_sheet):\n",
    "            xl = pd.read_excel(file ,sheet_name=sheet)\n",
    "            df = pd.DataFrame(xl)\n",
    "            job, date = job_date(df, file)\n",
    "            df.columns = df.iloc[2]\n",
    "            df = df.drop(df.index[:3])\n",
    "            df = df.iloc[:, :27]\n",
    "            df['updated'] = date\n",
    "            df['job'] = job\n",
    "            df['HJ Qty Comp'] = df['HJ Qty Comp'].fillna(0)\n",
    "            df = df.dropna(subset=['Qty'])\n",
    "            df = df.reset_index(drop=True)\n",
    "            df_list.append(df)\n",
    "    full_df = pd.concat(df_list).drop_duplicates().reset_index(drop=True)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fbafa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_path = r\"C:\\Users\\willd\\OneDrive\\Desktop\\Belair\\projection_analysis\\completed proj projections\"\n",
    "c_recents = r\"C:\\Users\\willd\\OneDrive\\Desktop\\Belair\\projection_analysis\\c_recent\\compiled_data.xlsx\"\n",
    "ew = r\"C:\\Users\\willd\\OneDrive\\Desktop\\Belair\\projection_analysis\\c_recent\\Earth_Work.xlsx\"\n",
    "\n",
    "on_going_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59d8fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_codes = job_code(completed_path)\n",
    "newest = lat_old(job_codes)\n",
    "full_df = files_to_dfs(newest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0150357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_15836\\4202732208.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_dup['Qty'] = no_dup['Qty'].astype(float)\n",
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_15836\\4202732208.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_dup['Actual Cost$'] = no_dup['Actual Cost$'].astype(float)\n",
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_15836\\4202732208.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_dup['Total Budget'] = no_dup['Total Budget'].astype(float)\n",
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_15836\\4202732208.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  earth_work['crew'] = 'misc.'\n"
     ]
    }
   ],
   "source": [
    "full_df['Ph Int'] = full_df['Phase Code'].astype(str).str[0]\n",
    "full_df = full_df[~full_df['updated'].isnull()]\n",
    "full_df['year'] = pd.DatetimeIndex(full_df['updated']).year\n",
    "full_df['month'] = pd.DatetimeIndex(full_df['updated']).month\n",
    "# full_df['Est unit $'] = full_df['Total Budget'] / full_df['Qty']\n",
    "# full_df['Act unit $'] = full_df['Actual Cost$'] / full_df['HJ Qty Comp']\n",
    "full_df = full_df.sort_values(by='updated', ascending=False)\n",
    "\n",
    "no_dup = full_df.drop_duplicates(subset=['Phase Code','Description','job'], keep='last')\n",
    "no_dup['Qty'] = no_dup['Qty'].astype(float)\n",
    "no_dup['Actual Cost$'] = no_dup['Actual Cost$'].astype(float)\n",
    "no_dup['Total Budget'] = no_dup['Total Budget'].astype(float)\n",
    "\n",
    "most_recent = no_dup.sort_values(by=['job', 'Phase Code'])\n",
    "most_recent = most_recent[~most_recent[['Qty','HJ Qty Comp']].eq(0).sum(1).ge(2)]\n",
    "\n",
    "earth_work = most_recent[most_recent['Ph Int'] == '3']\n",
    "demo = most_recent[most_recent['Ph Int'] == '6']\n",
    "\n",
    "earth_work['crew'] = 'misc.'\n",
    "\n",
    "for key, values in crew_dict.items():\n",
    "    earth_work.loc[earth_work['Description'].str.lower().str.contains('|'.join([x.lower() for x in values])), \"crew\"] = key\n",
    "\n",
    "reduced = earth_work.loc[:, earth_work.columns.notna()]\n",
    "reduced = reduced.drop(['% Comp', 'Notes','Lab','Eq', 'Reclass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bac1647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reduced\n",
    "test.loc[test['Total Budget'] > 0, 'Est UC'] = round(test['Total Budget'] / test['Qty'], 2)\n",
    "test.loc[test['Actual Cost$'] > 0, 'Act. UC'] = round(test['Actual Cost$'] / test['HJ Qty Comp'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a59ef279",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(c_recents, engine=\"xlsxwriter\")\n",
    "most_recent.to_excel(writer, sheet_name=\"mk1\")\n",
    "test.to_excel(writer, sheet_name=\"agg data\")\n",
    "# money_in.to_excel(writer, sheet_name=\"income\")\n",
    "# money_out.to_excel(writer, sheet_name=\"expense\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc65a9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10291-30 Stockyard Event Center NWC-A&P',\n",
       "       '10291-50 Stockyard Event Center NWC-A&P',\n",
       "       '10292-50 Sorrel Ranch-Lokal',\n",
       "       \"10298-30 Alta Sloan's Lake-Wood Partners\",\n",
       "       \"10298-50 Alta Sloan's Lake-Wood Partners\",\n",
       "       '10301-30 Columbine HS - Swinerton',\n",
       "       '10301-50 Columbine HS - Swinerton',\n",
       "       '10304- 30 - Mile High Greyhound Park Development-Crossland',\n",
       "       '10304- 50 - Mile High Greyhound Park Development-Crossland',\n",
       "       '10305-30 Evans & Holly - Lokal', '10308-30 The Cameron-CFC',\n",
       "       '10308-50 The Cameron-CFC',\n",
       "       '10310- 30 - Greyhound Park Apartments - Crossland',\n",
       "       '10310- 50 - Greyhound Park Apartments - Crossland',\n",
       "       '10312-50 National Jewish Center for Out Patient Health-Mortenson',\n",
       "       '10314-30 Denver Gateway East-Lokal',\n",
       "       '10315-30 Denver Gateway West-Lokal',\n",
       "       '10315-50 Denver Gateway West-Lokal',\n",
       "       '10316-30 Canvas @ Castle Rock-Watermark',\n",
       "       '10316-50 Canvas @ Castle Rock-Watermark',\n",
       "       '10317- 30 - Highline Village Townhomes - Alliance',\n",
       "       '10318-30 Dry Gulch Commons-Taylor Kohrs',\n",
       "       '10320-30 Stanley Residential - Alliance',\n",
       "       '10321-30 Chatfield Bluffs-Lokal',\n",
       "       '10321-50 Chatfield Bluffs-Lokal', '10325-30 StoneGate-Lokal',\n",
       "       '10329-30 Carvana-ArcoMurray', \"10336-30 Vic's Car Wash-Petra\",\n",
       "       '10339-30 Victory South-Colorado Springs-Lokal',\n",
       "       '10340-30 Lynwood Senior Apartments-Brinkman',\n",
       "       '10341-30 Qwest Thornton Central Storage - McCauley',\n",
       "       '10342-30 Canvas at Brighton - Contour',\n",
       "       '10344-30 Westray - Weitz', '10344-50 Westray - Weitz',\n",
       "       '10346-30 Range View Pond B-DBG',\n",
       "       '10350-30 Gateway Emblem - Lennar',\n",
       "       '10350-50 Gateway Emblem - Lennar', '10351-30 Montbello-A&P',\n",
       "       '10351-50 Montbello-A&P', '10352-30 A12 Thunder Vista - A&P',\n",
       "       '10369-50 Quik Trip Inlet Repairs - Roche'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(test['job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7844763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pipe Materials', 'Concrete / Thrust Blocks', 'Trench Boxes',\n",
       "       'Flash Fill', 'Core Drill', 'Inlet Sub',\n",
       "       'Wet Taps - (2) 4\" & (1) 8\"', 'Trench Box',\n",
       "       'Concrete & Thrust Blocks', 'Potholing', 'Street Sweeping',\n",
       "       'Traffic Control', 'Sawcutting', 'Asphalt/Concrete Sub',\n",
       "       'Video & Flush existing Sanitary Sewer',\n",
       "       'Video & Flush New Sanitary Sewer', 'Misc Hardware Store Items',\n",
       "       'Water', 'Ashalt Removal', 'Erosion Control Sub', 'Bowman',\n",
       "       'Davey Tree Service', 'Potholing - Tree Stumps',\n",
       "       'Asphalt Paving - Assumed 4\" Depth', 'Asphalt Paving',\n",
       "       'Concrete Paving - Sidewalk (4\" PCC)', 'Sidewalk',\n",
       "       'Asphalt Site Removals', 'Dana Kepner', 'Sweeping',\n",
       "       'Martin Marietta', 'Forterra', 'CIP Inlet', 'Bowman Supply',\n",
       "       'Concrete Sub', 'Lindsay Precast', 'Lange / Evoqua',\n",
       "       'Ewing Landscape', 'Asphalt Patch', 'Concrete Patch',\n",
       "       'Flash Fill - S. Dexter Street - Domestic Water Service, Fire',\n",
       "       'Crane',\n",
       "       'Traffic Control for Installation of Water, Fire, Hydrants &',\n",
       "       'ALL#1 ROW Permits', 'Trash Rack', 'Oldcastle Precast', 'Rebar',\n",
       "       'Debris', 'Concrete Removal', 'Asphalt Removal',\n",
       "       'Misc Demo - Flag Pole, Bike Racks, Separate Bricks from Dono',\n",
       "       'Utility Disconnects', 'Concrete Removals', 'Asphalt Removals',\n",
       "       'E10 12\" Storm Mainline', 'E10 18\" Storm Mainline',\n",
       "       'E10 Storm Inlet', 'G1 18\" Storm Mainline', 'G1 Storm Inlet',\n",
       "       'Storm G1 Install 18\" Tide Flex Valve', 'G1 Forebay (was 24\" FES)',\n",
       "       'G1 Storm Manhole', 'G2 18\" Storm Mainline', 'G2 Storm Inlet',\n",
       "       'G3 At Connection 30\" RCP CL-III 7\\'',\n",
       "       'G4/G5 Forebay (sas 48\" FES)', 'Remove & Replace Concrete',\n",
       "       'Remove & Replace Asphalt', 'Asbestos Pipe Removal',\n",
       "       'R&D Existing Pipe & 3 Area Drains', 'Debris Disposal',\n",
       "       'C&G Removal', 'R&D Ex Inlet 1 EA EX Inlet D2C', 'Remove Concrete',\n",
       "       'Remove Asphalt', 'Tree & Debris Removal',\n",
       "       'Remove Curb & Gutter 400 Lf', 'Remove Sidewalk', 'Misc Demo',\n",
       "       'Site Removals', 'Concrete Site Removals', 'Retaining Wall Demo',\n",
       "       'Rem & Cap Fire Line', 'Rem 2\" Dom Copper',\n",
       "       'Off Site Concrete Removals', 'Trees 4 Total',\n",
       "       'Remove Asphalt 1520 SF', 'ROW Tree & Debris Removal',\n",
       "       'ROW Asphalt Site Removals', 'ROW Concrete Site Removals',\n",
       "       'R&D existing Pipe', 'R&D Storm Manhole', 'R&D Headwall',\n",
       "       'R&D Type R Inlet', \"R&D 6'x3' RCBC (17')\", 'R&D Rip Rap (720 SF)',\n",
       "       'R&D Concrete', 'R&D Asphalt', 'R&D Exist 30\" RCP / FES',\n",
       "       'R&D Debris', 'Tree & Debris Removal Small Trees And Shrubs',\n",
       "       'ROW Driveway Removals', 'ROW C&G Removals', 'R&D Existing Inlet',\n",
       "       'Tree Removal', 'Tennis And Basketball Courts', 'North Wall Demo',\n",
       "       'Remove Existing Inlet', 'R&D Concrete & C&G', 'Misc Demo Shrubs',\n",
       "       'R&D Concrete 6,615 SF', 'R&D Asphalt 4\" Depth 10,792 SF',\n",
       "       'R&D Concrete Base 73.44 TONS',\n",
       "       'R&D Reinforced Concrete Slab 1,751 SF', 'R&D Concrete Curb Wall'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(demo['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae2c7400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo[demo['HJ Qty Comp'] > demo['Qty']]\n",
    "# demo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490f84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"D:\\belair\\completed proj projections\\Projection 10340-30-50 Lynwood Sr Apts-Brinkman 20230116 - CR.xlsx\"\n",
    "xl = pd.read_excel(file ,sheet_name=0)\n",
    "df = pd.DataFrame(xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc129fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                                  Non-Null Count  Dtype  \n",
      "---  ------                                                  --------------  -----  \n",
      " 0   Projection 10340-30 Lynwood Senior Apartments-Brinkman  49 non-null     object \n",
      " 1   Unnamed: 1                                              35 non-null     object \n",
      " 2   Unnamed: 2                                              11 non-null     object \n",
      " 3   Unnamed: 3                                              35 non-null     object \n",
      " 4   Unnamed: 4                                              15 non-null     object \n",
      " 5   Unnamed: 5                                              35 non-null     object \n",
      " 6   Unnamed: 6                                              26 non-null     object \n",
      " 7   Unnamed: 7                                              0 non-null      float64\n",
      " 8   Unnamed: 8                                              38 non-null     object \n",
      " 9   Unnamed: 9                                              2 non-null      object \n",
      " 10  Unnamed: 10                                             38 non-null     object \n",
      " 11  Unnamed: 11                                             36 non-null     object \n",
      " 12  Unnamed: 12                                             36 non-null     object \n",
      " 13  Unnamed: 13                                             36 non-null     object \n",
      " 14  Unnamed: 14                                             38 non-null     object \n",
      " 15  Unnamed: 15                                             36 non-null     object \n",
      " 16  Unnamed: 16                                             37 non-null     object \n",
      " 17  Unnamed: 17                                             0 non-null      float64\n",
      " 18  Unnamed: 18                                             6 non-null      object \n",
      " 19  Unnamed: 19                                             4 non-null      object \n",
      " 20  Unnamed: 20                                             5 non-null      object \n",
      " 21  Unnamed: 21                                             3 non-null      object \n",
      " 22  Unnamed: 22                                             36 non-null     object \n",
      " 23  Unnamed: 23                                             0 non-null      float64\n",
      " 24  Unnamed: 24                                             37 non-null     object \n",
      " 25  Unnamed: 25                                             0 non-null      float64\n",
      " 26  Unnamed: 26                                             38 non-null     object \n",
      " 27  Unnamed: 27                                             36 non-null     object \n",
      " 28  Unnamed: 28                                             37 non-null     object \n",
      " 29  Unnamed: 29                                             36 non-null     object \n",
      " 30  Unnamed: 30                                             0 non-null      float64\n",
      " 31  Unnamed: 31                                             38 non-null     object \n",
      "dtypes: float64(5), object(27)\n",
      "memory usage: 13.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33c88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea410ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef2c7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[['Est UC', 'Act. UC']].astype(float)\n",
    "df[['Est UC', 'Act. UC']] = df[['Est UC', 'Act. UC']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76b297b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\willd\\OneDrive\\Desktop\\Belair\\projection_analysis\\c_recent\\compiled_data ud.xlsx\"\n",
    "xl1 = pd.read_excel(file ,sheet_name=1)\n",
    "most_recent = pd.DataFrame(xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfef6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(c_recents, engine=\"xlsxwriter\")\n",
    "most_recent.to_excel(writer, sheet_name=\"mk1\")\n",
    "df.to_excel(writer, sheet_name=\"agg data\")\n",
    "# money_in.to_excel(writer, sheet_name=\"income\")\n",
    "# money_out.to_excel(writer, sheet_name=\"expense\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eb5c7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3624"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0e466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850d7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36d542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888714d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fab617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = r\"C:\\Users\\willd\\OneDrive\\Desktop\\Belair\\projection_analysis\\completed proj projections\\Projection 10304-50 Greyhound-Crossland 20220126.xlsx\"\n",
    "# xl = pd.read_excel(file ,sheet_name=1)\n",
    "# most_recent = pd.DataFrame(xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "851c3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "ew_ = [x for x in job_code(completed_path) if '-30' in x]\n",
    "unique_cod = sorted(pd.unique([x[0] for x in (x.split(\"-\") for x in ew_)]))\n",
    "ew_code = [x for x in test['job'] if '-30' in x]\n",
    "unique_codes = sorted(pd.unique([x[0] for x in (x.split(\"-\") for x in ew_code)]))\n",
    "# print(unique_codes)\n",
    "# print(unique_cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c928fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ful = files_to_dfs(newest)\n",
    "ew_code = [x for x in ful['job'] if '-30' in x.replace(' ', '')]\n",
    "unique_codes = sorted(pd.unique([x[0] for x in (x.split(\"-\") for x in ew_code)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a10d3edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# print(len(unique_codes))\n",
    "# print(len(unique_cod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1a0ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_codes))\n",
    "print(len(unique_cod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d53a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for oldest/newest\n",
    "\n",
    "# def old_new_col(df, chron):\n",
    "#     df = df.rename(columns={\"Qty\": (chron + \" Qty\"), \"Total Budget\": (chron + \" Total Budget\")})\n",
    "#     return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da2dc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat = old_new_col(lat_test, \"Latest\")\n",
    "# old = old_new_col(old_test, \"Oldest\")\n",
    "# old = old[['Phase Code', 'Description', 'Oldest Qty', 'Oldest Total Budget', 'job']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a20fa572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = lat.join(old.set_index('Phase Code'), on=['Phase Code', 'Description'], validate='m:1')\n",
    "# full_df = pd.merge(lat,old, how='left', on=['Phase Code', 'Description'])\n",
    "# full_df = pd.merge(lat,old, how='left', \n",
    "#                   left_on=['Phase Code', 'Description', 'job'],\n",
    "#                   right_on=['Phase Code', 'Description', 'job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ccc4514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a414ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = []\n",
    "# for item in os.listdir(completed_path):\n",
    "#     job_code = item.split(' ')[1]\n",
    "#     files.append(job_code)\n",
    "# files= pd.unique(files)\n",
    "    \n",
    "#     full_path = os.path.join(completed_path, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2234985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_file_list = []\n",
    "# for file in files:\n",
    "#     job_files = [os.path.join(completed_path, x) for x in os.listdir(completed_path) if file in x]\n",
    "#     latest_file = max(job_files, key=os.path.getctime)\n",
    "#     latest_file_list.append(latest_file)\n",
    "# latest_file_list = pd.unique(latest_file_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2829b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# for item in latest_file_list:\n",
    "#     num_sheet = len(pd.ExcelFile(item).sheet_names)\n",
    "#     for sheet in range(0,num_sheet):\n",
    "#         xl = pd.read_excel(item ,sheet_name=sheet)\n",
    "#         df = pd.DataFrame(xl)\n",
    "#         job, date = job_date(df)\n",
    "#         df.columns = df.iloc[2]\n",
    "#         df = df.drop(df.index[:3])\n",
    "#         df = df.iloc[:, :27]\n",
    "#         df['updated'] = date\n",
    "#         df['job'] = job\n",
    "#         df['HJ Qty Comp'] = df['HJ Qty Comp'].fillna(0)\n",
    "#         df = df.dropna(subset=['Qty'])\n",
    "#         df = df.reset_index(drop=True)\n",
    "#         df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cada2f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_6548\\2810187377.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_df['year'] = pd.DatetimeIndex(full_df['updated']).year\n",
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_6548\\2810187377.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_df['month'] = pd.DatetimeIndex(full_df['updated']).month\n"
     ]
    }
   ],
   "source": [
    "# full_df = pd.concat(df_list).drop_duplicates().reset_index(drop=True)\n",
    "full_df['Ph Int'] = full_df['Phase Code'].astype(str).str[0]\n",
    "full_df = full_df[~full_df['updated'].isnull()]\n",
    "full_df['year'] = pd.DatetimeIndex(full_df['updated']).year\n",
    "full_df['month'] = pd.DatetimeIndex(full_df['updated']).month\n",
    "# full_df['Est unit $'] = full_df['Total Budget'] / full_df['Qty']\n",
    "# full_df['Act unit $'] = full_df['Actual Cost$'] / full_df['HJ Qty Comp']\n",
    "full_df = full_df.sort_values(by='updated', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84f0ab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_6548\\3602641939.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_dup['Latest Qty'] = no_dup['Latest Qty'].astype(float)\n",
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_6548\\3602641939.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_dup['Actual Cost$'] = no_dup['Actual Cost$'].astype(float)\n",
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_6548\\3602641939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_dup['Latest Total Budget'] = no_dup['Latest Total Budget'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "# full_df = full_df[~full_df['updated'].isnull()]\n",
    "# first = full_df.drop_duplicates(subset=['Phase Code','Description','job'], keep='first')\n",
    "# last = full_df.drop_duplicates(subset=['Phase Code','Description','job'], keep='last')\n",
    "\n",
    "######\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "\n",
    "#######\n",
    "no_dup = full_df.drop_duplicates(subset=['Phase Code','Description','job'], keep='last')\n",
    "no_dup['Latest Qty'] = no_dup['Latest Qty'].astype(float)\n",
    "no_dup['Actual Cost$'] = no_dup['Actual Cost$'].astype(float)\n",
    "no_dup['Latest Total Budget'] = no_dup['Latest Total Budget'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ece2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent = no_dup.sort_values(by=['job', 'Phase Code'])\n",
    "most_recent = most_recent[~most_recent[['Latest Qty','HJ Qty Comp']].eq(0).sum(1).ge(2)]\n",
    "# df.drop_duplicates(subset=['IDName'], keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b86ba240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of just earthwork\n",
    "earth_work = most_recent[most_recent['Ph Int'] == '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41ea82f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_dict = {\"Scarify\":[\"Scarify\"], \"Strip Site\":[\"Strip Site\"], \n",
    "             \"Soil Correction\":[\"Soil Correction\", \"OX\",\"OE\", \"Over Ex\", \"Excavate & Re-compact\", \"Over-Ex\", \"Excavate & Recompact\"],\n",
    "             \"Ex Retainining Wall\":[\"Excavate Site Retaining\", \"Excavate MSE\", \"Exc Retaining\", \"Exc Site Retn Walls\"],\n",
    "             \"Export\":[\"Export\", \"Exp\"], \"Import\":[\"Import\", \"Imp\"],\n",
    "             \"Ex Frost footing\": [\"Exc Fro\", \"Excavate Fro\", \"Footing Excavation\"], \n",
    "             \"Ex Trash Enc\":[\"Excavate Trash\", \"Exc Trash\"],\n",
    "             \"Cut to Fill\":[\"Cut To Fill\", \"Utility Spoils - Site Fill\", \"Building Pad Fill w/ Spoils\"],\n",
    "             \"Cut to Stockpile\":[\"Cut to Stockpile\", \"Load & Stockpile\"],\n",
    "             \"Handle spoils\":[\"Handle Utility Spoils\", \"Handle Foundation Spoils\", \"Handle Spoils\", \"Handle & Stockpile\"],\n",
    "             \"Double Handle\":[\"Double Handle\"], \"Cut in C&G\":[\"Cut In C\", \"Cut-in C\", \"Grade C&G\"],\n",
    "             \"Ex Elevator\":[\"Excavate Elevator\"],\n",
    "             \"Grade Landscape\":[\"grade Landscape\", \"grade Green\", \"Landscape\"],\n",
    "             \"Grade Parkinglots and Roads\":[\"Grade Boulevards\",\"Grade Asphalt\", \"Grade Parking\", \"Grade Pkg\", \"Grade Main Roads\"],\n",
    "             \"Grade SW\":[\"Grade Sidewalks\", \"Grade Walks\", \"Exterior Slabs\", \"grade Brick Pavers\", \"Grade SW\"],\n",
    "             \"Export\":[\"Export\"],\n",
    "             \"Grade BLDG\": [\"Grade Bldg\", \"Grade Building\", \"Grade Structural\"],\n",
    "             \"Drain Tile\":[\"Drain\"],\n",
    "             \"Backfill Int\":[\"Backfill Int\", \"Footing Backfill\"],\n",
    "             \"Backfill Ext\":[\"Backfill Ext\"],\n",
    "             \"Backfill Elevator\":[\"Backfill Elevator\"],\n",
    "             \"Backfill Trash\":[\"Backfill Trash\"], \"Backfill Frost\": [\"Backfill Frost\"],\n",
    "             \"High Backfill\": [\"High Backfill\"], \"Grade Class X\":[\"Grade Class\"],\n",
    "             \"Excavate Interior\":[\"Excavate Int\", \"Excavate Thickened\", \"Excavate Grade Beams\", \"Exc Int\"],\n",
    "             \"Excavate Exterior\":[\"Excavate Ext\", \"Exc Ext\"], \"Grade Pond\":[\"Basin Grading\",\"Grade Pond\" , \"Grade Detention Pond\"],\n",
    "             \"Assist shoring\":[\"Assist Shoring\"],\n",
    "             \"Stairs\":[\"Stairs\"], \"Place Strippings\":[\"Place Stripping\"],\n",
    "             \"Street Sweep\":[\"Street Sweeping\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fdfe0460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_6548\\2156627274.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['crew'] = 'misc.'\n"
     ]
    }
   ],
   "source": [
    "test = earth_work\n",
    "test['crew'] = 'misc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "946e584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in crew_dict.items():\n",
    "    test.loc[test['Description'].str.lower().str.contains('|'.join([x.lower() for x in values])), \"crew\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c518b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = test.loc[:, test.columns.notna()]\n",
    "reduced = reduced.drop(['Notes','Lab','Eq', 'Reclass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9631136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = most_recent.Description.value_counts()\n",
    "# agg_df = most_recent[most_recent.Description.isin(v.index[v.gt(3)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e55df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(c_recents, engine=\"xlsxwriter\")\n",
    "most_recent.to_excel(writer, sheet_name=\"mk1\")\n",
    "reduced.to_excel(writer, sheet_name=\"agg data\")\n",
    "# money_in.to_excel(writer, sheet_name=\"income\")\n",
    "# money_out.to_excel(writer, sheet_name=\"expense\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8eef1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2ca7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
